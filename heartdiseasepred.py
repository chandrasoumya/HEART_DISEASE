# -*- coding: utf-8 -*-
"""HeartDiseasePred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pgK61OrYieqF2viPdpAmCkI0k6cqD7CE
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import joblib

# Load the dataset
data = pd.read_csv('dataset.csv')

# Step 1: Data Cleaning
# Replace cholesterol values of 0 with NaN
data['cholesterol'] = data['cholesterol'].replace(0, np.nan)
# Impute missing cholesterol values with the median
data['cholesterol'] = data['cholesterol'].fillna(data['cholesterol'].median())

# Define feature columns and target
features = ['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol',
            'fasting blood sugar', 'resting ecg', 'max heart rate',
            'exercise angina', 'oldpeak', 'ST slope']
target = 'target'

# Split features into numerical and categorical
numerical_features = ['age', 'resting bp s', 'cholesterol', 'max heart rate', 'oldpeak']
categorical_features = ['sex', 'chest pain type', 'fasting blood sugar',
                       'resting ecg', 'exercise angina', 'ST slope']

# Step 2: Preprocessing
# Separate numerical and categorical data
X_numerical = data[numerical_features]
X_categorical = data[categorical_features]

# Scale numerical features
scaler = StandardScaler()
X_numerical_scaled = scaler.fit_transform(X_numerical)
X_numerical_scaled = pd.DataFrame(X_numerical_scaled, columns=numerical_features)

# One-hot encode categorical features
encoder = OneHotEncoder(drop='first', sparse_output=False)
X_categorical_encoded = encoder.fit_transform(X_categorical)
categorical_encoded_columns = encoder.get_feature_names_out(categorical_features)
X_categorical_encoded = pd.DataFrame(X_categorical_encoded, columns=categorical_encoded_columns)

# Combine numerical and categorical features
X = pd.concat([X_numerical_scaled, X_categorical_encoded], axis=1)
y = data[target]

# Step 3: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Train the Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 5: Save the Model, Scaler, and Encoder
joblib.dump(model, 'heart_disease_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(encoder, 'encoder.pkl')

print("Model, scaler, and encoder saved successfully.")